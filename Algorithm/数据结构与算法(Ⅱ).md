# 二叉搜索树(Binary Search Tree, BST)
- 特征
	- 一个BST的左子树的所有节点的值都不大于根节点
	- 右子树的所有节点的值都不小于根节点
	
- 通常BST规定不允许存在key相同的节点
	- 如Java中的Map不允许存在key相同的键值对
	- Python中的dict不允许存在key相同的键值对
	
- 查找

		```java
	// 找不到返回null
	Node search(Node root, int key) {
	    Node next = root;
	    while (next != null) {
	        if (next.getKey() > key) {
	            next = next.getLeftChild();
	        } else if (next.getKey() < key) {
	            next = next.getRightChild();
	        } else {
	            return next;
	        }
	    }
	    return null;
	}
	```
	
	
	
- 添加/更新

		```java
	// 当node的key存在时更新, 当node的key不存在时添加
	void put(int key, int value) {
	    Node result = 查找,找不到返回最后一个节点(key);
	    if (result.getKey() > key) {
	        result.setLeftChild(new Node(key, value, result));
	    } else if (result.getKey() < key) {
	        result.setRightChild(new Node(key, value, result));
	    } else {
	        result.setValue(value);
	    }
	}
	```
	
	
	
- 删除
	
	- ![dETxu4.png](https://s1.ax1x.com/2020/08/16/dETxu4.png)
## 平衡二叉搜索树(Banlanced Binary Search Tree, BBST)
- 意义
	- BST的查找/添加/删除的时间复杂度都是O(树高)
	- 当树的高度尽量的小时, BST的效率最高
	- BBST是BST的一个子集, 其增删查操作的时间复杂度为O(logn)
- 等价BST
	- 多个BST的中序遍历得到的线性序列可能是相同的
	- 这些BST称为等价BST
- BST等价变化
	- BST等价变化的转换规则
		- 上下可变: 连接关系不尽相同, 继袭关系可能颠倒
		- 左右不乱: 中序遍历序列完全一致
	- BST之间的等价变换都可以看做是由一系列的两种基础操作变换得到的
		- zig: 顺时针旋转变换
			- ![dEygQP.png](https://s1.ax1x.com/2020/08/16/dEygQP.png)
		- zag: 逆时针旋转变换
			- ![dEyhdg.png](https://s1.ax1x.com/2020/08/16/dEyhdg.png)
	- 对任何一种BBST的等价变换的要求
		- 对于单个zig/zag操作, 其时间复杂度需要为O(1)
		- 对于增/删并且保持自身依然为BBST的操作, 其时间复杂度最坏为O(logn)
# AVL树
- AVL树是一种BBST
- 平衡因子
	- 对于一个节点, 其平衡因子 = 左子树高度 - 右子树高度
	- AVL树规定, 对于任意的节点, 其平衡因子的绝对值 <= 1
- 插入/更新
	- AVL树在插入一个节点后, 只需要做一些固定的zig/zag操作即可恢复平衡
	- 因此插入操作后只需要O(1)的时间就可以恢复平衡
- 删除
	- AVL树在删除一个节点后, 可以通过固定的操作使一个局部平衡
	- 但是这个使局部的操作可能会使一个更大的局部失去平衡
	- 这就需要对这个更大的局部进行操作使其平衡
	- 这种失衡传播的现象可能会传播O(logn)次
	- 因此删除操作后, 最坏需要O(logn)的时间才能使整个树重新恢复平衡
- 3+4重构
	- 注意到: 只要是一棵树失衡, 不论是哪种情况, 其最终通过等价变换所达到的重新平衡的树的构成都是一致的
		- ![dVpMIU.png](https://s1.ax1x.com/2020/08/16/dVpMIU.png)
	- 因此, 想让一棵树重新恢复平衡, 就只需要明确这棵树的a, b, c这三个节点, 以及T0, T1, T2, T3这四棵树, 然后让这三个节点和四棵树重构为上图所示的结构
	- 这样不管原来树是以哪种情况失衡的, 其恢复平衡的操作都是一致的, 十分便于维护
	- 案例
		- ![dVCSN8.png](https://s1.ax1x.com/2020/08/16/dVCSN8.png)
		- 其中v对应3+4重构中的a, p对应b, g对应c, T0对应T0, T1对应T1, T2对应T2, T3对应T3
# 伸展树(Splay Tree)
- 伸展树是平衡条件比AVL数更加宽松的BBST
- 伸展
	- 将一个节点调整至树根的操作称为伸展
	- 伸展树中, 若一个节点被访问, 则就会对这个节点进行一次伸展
	- 经过若干次访问(伸展)后, 访问频率最大的那一些节点就会集中在树的上层
	- 而树的上层的访问效率是最高的, 则树整体的访问性能就会提高
- 单层调整 vs 双层调整
	- 单层调整
		- 通过一次次地对被访问节点的父亲节点进行zig/zag实现被访问节点的上移
		- 这样的上移策略的分摊访问效率最坏时间复杂度为Ω(n)
	- 双层调整
		- 每轮调整先将被访问节点的祖父节点进行zig/zag, 再对被访问节点的新的父亲节点进行zig/zag
		- 这样的上移策略的分摊访问效率时间复杂度为O(logn)
		- 其效率提升的奥秘就是一个节点在上升至树根时会将其上升路径所对应的树层数折半
- 伸展树的另一个优势是每个节点不需要记录用于平衡树的冗余信息
- 缺点
	- 伸展树不能保证单次最坏情况不出现
	- 即不使用于效率敏感的场合
# B树(B-Tree)
- Preface
	- 越来越小的内存
		- 虽然内存的大小在不断增加
		- 但是数据的增长数据远大于内存
		- 因此, 对于单位数据来讲, 其所支配的内存越来越小
	- 一秒与一天
		- 对于不同类型的容器, 其访问速度差异悬殊
		- 如, 对于磁盘来说其访问速度在ms量级, 而对于内存来说其访问速度在ns量级
		- 两者相差至少5个数量积
		- 即1秒与1天的差异
	- 存储系统的分级组织
		- 根据存储容器访问速度的不同, 将存储容器分为不同的级别(如一级缓存, 二级缓存...)
		- 访问越频繁的数据存储在访问速度越高的容器中
		- 而通常访问速度越高的容器, 其容量越低
		- 如电脑的寄存器, RAM, 磁盘
		- I/O
			- 不同存储级别的容器之间的数据交换叫做I/O
		- 外存访问
			- 对高存储级别而言, 其对低存储级别的访问都叫外存访问
			- 而一般地, 外存访问特指对内存对磁盘的访问
	- 批量式访问
		- 当内存从磁盘中读取数据, 其读写1B与读写1KB所消耗的时间成本几乎是相同的
		- 因此我们通常使用缓冲区, 以页(page)或块(block)为单位进行I/O
- B树
	- B树严格上讲并不是BST, 其一个节点可以有两个以上的子节点
	- 但是其本质与BST相同
	- 一层B树的节点可以看做是多层BST的合并
- B树的节点
	- 合并的优点
		- B树的节点可以看做是多层BST的父节点的合并
		- 这样做的目的是, 其节点的合并可以减少I/O次数
		- 即原来BST读入n个节点需要做n次I/O, 但是现在B树可能只需要1次I/O
	- 节点的大小
		- 节点中关键码的数量视磁盘的数据块大小而定
		- 目前多数数据库一个节点采用200-300个关键码
- B树的阶数
	- 所谓m阶B树, 就是m路BST(m >= 2)
	- 分支的个数
		- 内部非根节点
			- m阶B树需要内部节点的分支数不超过m, 不小于m/2向上取整
		- 根节点
			- m >= 分支数 >= 2
	- 对于m阶B树, 也叫(⌈m/2⌉, m)树
- B树的外部节点和叶节点
	- 外部节点
		- 没有数值(数据)的, 其实并不存在的末端节点
	- 叶节点
		- 真实存在的末端节点
	- 在其他一些树中, 外部节点和叶节点是一样的
	- B树中外部节点/叶节点的深度相同
	- B树的高度取决于外部节点, 即叶节点深度+1
# 红黑树

- 红&黑节点

  - 树根: 黑色
  - 外部节点: 黑色
  - 其余节点: 只有黑孩子(孩子不足两个的添加假想的外部节点)的为红节点

  - 外部节点到根节点所经过的黑色节点(不包括假想的外部节点)数目相等
    - 该数目被称为黑深度

- 提升变换

  - 定义
    - 将红黑树中的所有红节点提升至与其父节点同级
  - 特点
    - 经过提示变换后的红黑树, 其所有外部节点的层数变为一致

  - 提升变换之后的红黑树, 就是一棵(2, 4)树
    - 红黑节点每种情况的组合, 都对应(2, 4)树的一种节点

- 插入(双红)修正

  - 只需要做固定次数的zig/zag
  - 需要做最多O(logn)次的重染色

- 删除(双黑)修正
  - 只需要做固定次数以内的zig/zag
  - 需要做最多O(logn)次的重染色

- 持久性结构(Persistent structure)
  - 定义
    - 支持对任意历史版本进行访问(查找)的数据结构
  - Ephemeral
    - 数组, AVL树等数据结构, 都不是持久性结构, 因为一次删除/插入操作可能会导致其拓扑结构发生巨大的改变
    - 因此存储其各个历史版本需要占用大量的空间
  - 红黑树是持久性结构
    - 不论是双红修正还是双黑修正, 其拓扑结构都是O(1)的变化
    - 存储其历史结构就只需要在上一个历史版本的基础上做局部的修改

# 词典

- bucket桶
  - 直接存放或者间接指向一个词条
- bucket array桶数组
  - 由桶构成的数组
  - 也叫hash table哈希表/散列表
- hashing散列/定址/杂凑
  - 根据词条的key直接确定词条在散列表中的位置(bucket address散列地址)
  - 实现这个功能的函数叫做散列函数hash()
- load factor装填因子
  - λ = N/M
  - N为真正存储的词条个数
  - M为桶数组的大小

- hash collision散列冲突
  - 不同的key通过散列函数得到了同一个位置

## 散列函数

### 散列函数应该具备的性质

- determinism确定
  - 同一关键码总是被映射至同一地址
- efficiency快速
  - 散列函数的时间复杂度应该达到O(1)
- surjection满射
  - 散列函数得到的地址应该尽可能充分地覆盖整个散列空间
- uniformity均匀
  - 关键码映射到散列表各位置的概念应该尽量接近
  - 从而避免聚集(clustering)现象

### 常见的散列方法

  - 除余法

      - hash(key) = key % M
      - 若M = 2^k
          - key % M等价于key & (M - 1)
          - 但这样发生散列冲突的可能性会很大
      - 若M为素数
          - 这时散列表的覆盖最充分, 分布最均匀

  - MAD法

      - MAD法是对除余法的改进
      - 除余法的缺点
          - 不动点: 无论M取何值, 当key为0时, 总有hash(0) = 0
          - 零阶均匀: [0, R)的关键码, 平均分配至M个同, 但相邻的关键码的散列地址也必然相邻
      - MAD的hash(key) = (a * key + b) % M
          - M为素数
          - a > 0, b > 0
          - a % M ≠ 0

    - MAD法的优点
      - 解决了除余法中的不动点
      - 将零阶均匀变为了一阶均匀: 相邻的关键码的散列地址不相邻

- selecting digits数值分析法
  - 抽取key中的某几位, 构成地址
- mid-square平方取中法
  - 取key^2的中间的若干位, 构成地址

- folding折叠法
  - 将key分割成等宽的若干段, 取其总和作为地址
- XOR位异或法
  - 将key分割成等宽的二进制段, 经异或运算作为地址
- 随机法
  - 借用随机数生成的算法来得到散列地址的方法

### hashCode

- 散列算法通常研究的是将整数的key通过算法得到散列地址
- 而在实际应用中, key不一定是整数(如字符串)
- 因此散列函数需要先将key转为整数, 再交给散列算法
- 这个被转为整数的值就叫hashCode

## 散列冲突的排解

- *以下涉及系统高速缓存, 以及数论相关知识*

- linked-list chaining独立链

  - 每个桶中存放的是由一个个词条组成的链表
  - 多个散列地址相同的词条就会被存储在相应桶的链表中

- open addressing开放定址

  - 独立链的缺点
    - 桶中的链的内存不是连续的, 遍历时不是在访问一块连续的内存, 这导致链大概率不会在系统的高速缓存中, 从而难以高效率地遍历
  - 开放定址
    - 不同于closed addressing, 通过key不能直接确定这个词条所在的桶
    - 为每个桶都事先约定若干备用桶
    - 它们构成一个查找链(probing sequence/chain)
    - open addressing又称为closed hashing

  - linear probing线性试探
    - 当发现通过key确定的散列地址已经被占用, 则尝试后一个相邻桶, 直到达到空桶
      - 即`hash(key) -> hash(key) + 1 -> hash(key) + 2 ...`
    - 优点
      - 每次的查找都是在访问一块连续的内存, 可以充分利用系统的高速缓存
    - 缺点
      - 遍历时间复杂度 > O(1)
      - 以往的冲突, 会导致后续的冲突
    - lazy delete懒删除
      - 在删除一个词条时, 若直接将其删除, 则会导致查找链断裂, 从而影响后续的查找
      - 因此在删除操作中, 并不是直接将这个词条删除, 而是给这个词条做一个标记, 在查找时跳过并继续, 而在添加时被视为空桶而覆盖

  - quadratic probing平方试探
    - 与线性试探不同, 平方试探的尝试地址为`hash(key) -> hash(key) + 1^2 -> hash(key) + 2^2 -> ...`
    - 这样的以平方数为间隔的试探可以减轻因地址被占用而产生的局部堆积
    - 但是这样的试探不能保证能够被试探到的地址覆盖整个散列表
      - 可以证明, 当M取做素数, 且λ <= 0.5时能够保证试探地址遍布整个散列表
    - 平方试探对系统高速缓存的影响
      - 由于平方试探让每次的试探跨度增加, 则有可能导致试探超出缓存片, 进而引起I/O
      - 但是这种概率是比较小的
      - 假设系统的缓存片为1KB, 而词条(如指针)的大小为4B, 则需要连续冲突16次才会超出缓存片
  - 双向试探
    - 双向试探的尝试地址为`hash(key) -> hash(key) + 1^2 -> hash(key) - 1^2 -> hash(key) + 2^2 -> hash(key) - 2^2 -> ...`
    - 通过这样双向的平方试探的方式, 可以有效提高λ
    - 但是同样为了能够遍布整个散列表, 要求M为素数, 且M = 4k + 3(k = 0, 1, 2, ...)

## 计数排序(CountingSort)

- 适用场景
  - 线性序列中的元素的种类n << 线性序列的长度M
  - 即线性序列中有大量重复的元素
- 大致步骤
  - O(n)内遍历线性序列, 统计出每个种类的元素出现的次数, 并据此得到每个元素的积分(包括自己的出现次数, 以及比自己小的种类的所有出现次数)
  - 通过积分得到每个种类的元素出现在被排序序列中的范围: `[比自己小的最大种类的积分, 自己的积分)`
  - 通过上述范围得到有序序列

# 优先级队列(PriorityQueue)

- 基本功能定义

  ```java
  public interface PriorityQueue {
      // 插入元素, 并指定优先级
      void insert(Ele element, Pri priority);
      // 获得优先级最大的元素
      Ele getMax();
      // 删除优先级最大的元素
      void delMax();
  }
  ```




## 完全二叉堆(Complete Binary Heap)

- partial order部分有序/非完全有序

  - 根据优先级队列的功能定义, 其关注点只在于优先级最大的那个元素
  - 因此只需要以一个相对低廉的成本维护一个非完全有序的序列, 就可以达到目的
  - 这样的序列的实现之一就是完全二叉堆

- Complete Binary Tree完全二叉树

  - 任意平衡因子都为非负的AVL树
  - 即只有最后一层的右边部分出现连续的空缺的二叉树

- Complete Binary Heap完全二叉堆

  - 得益于完全二叉树结构上的紧凑性, 一颗完全二叉树可以通过Vector向量来实现, 这样的向量又称为完全二叉堆, 简称二叉堆(可以理解为完全二叉树就是完全二叉堆的逻辑结构)

  - 节点在向量中存储的顺序, 就对应于完全二叉树的层次遍历顺序

  - 并且有

    ```java
    Rank parent(Rank i) {
        return (i - 1) >> 1;
    }
    Rank LeftChild(Rank i) {
        return (i << i) + 1;
    }
    Rank RightChild(Rank i) {
        return ((i + 1) << 1); // (i << 1) + 2
    }
    ```

    

- 堆序性
  - 规定: 对于任意的父节点, 其优先级都必须大于其子节点
  - 由堆序性可得, 优先级队列所关注的最大优先级元素, 就是完全二叉树的根节点, 即完全二叉堆的第一个元素

- insert

  - 大致步骤
      1. 在完全二叉堆末尾插入词条
      2. 比较其父亲节点与本节点的优先级, 若违反堆序性则将两者交换
      3. 比较新父亲节点, 重复步骤2
  - percolate up上滤
      - 词条逐层上升的过程
  - 效率
      - 最坏时间复杂度: O(logn), 对应于完全二叉树的树高
      - 平均时间复杂度: O(1), 平均每个节点上升的高度为O(1)
  
- delMax

  - 大致步骤

    1. 删除完全二叉堆的第一个元素, 将最后一个元素移至第一个位置

    2. 比较其子节点与本节点的优先级, 若违反堆序性则将子节点的最大者与本节点交换

    3. 比较新的子节点, 重复步骤2

  - percolate down下滤

    - 词条逐层下降的过程

  - 效率

    - 最坏时间复杂度: O(logn)

- heapification普通向量转化为完全二叉堆

  - 大致步骤
    - 在完全二叉堆中从后到前, 依次对内部节点进行下滤
  - 效率
    - T(n) = ∑height(i) = O(n)

- heapSort堆排序

  - 堆排序——使用最大二叉堆的selectionSort选择排序

    - 选择排序将整个向量分为unsorted部分和sorted部分
    - 一般的选择排序的unsorted部分为普通向量, 因此在其中选择出最大值需要O(n)的时间
    - 而堆排序则是将unsorted部分换为最大二叉堆, 因此在其中选择出最大值只需要O(logn)时间
    - 因此堆排序的时间复杂度为O(nlogn)

  - 大致步骤

    1. 将需要排序的向量转化为完全二叉堆, 此时整个向量为unstorted部分

    2. 选择出unstorted部分的最大值, 让其与storted部分的前一个未排序元素交换
    3. 将unstorted部分的第一个元素进行下滤
    4. 重复2, 3步骤, 直到storted部分占满整个向量

## 左式堆/左倾堆(Leftist Heap)

- 左式堆与完全二叉堆的区别
  - 左式堆抛弃了完全二叉堆的结构性, 而保留了其堆序性
  - 左式堆就是在元素插入时添加了某种规则, 使左式堆倾向于将更多的节点放在左侧分支(注意不是绝对)

- Null Path Length空节点路径长度
  - npl(null) = 0
  - npl(x) = 1 + min(npl(x.leftChild) + npl(x.rightChild))
  - npl(x)即为x到假想的外部节点的最近距离
  - npl(x)也为以x为根的最大满子树的高度

- 左式堆的定义
  - 对于任何一个节点, 其npl(左孩子) >= npl(右孩子)
  - 推论: 对于任何一个节点, 其npl(x) = npl(x.rightChild) + 1

- 左式堆的右侧链
  - 由左式堆的定义可以得到, 右侧链的终点必然是全堆中最浅的外部节点
  - 若右侧链长为d, 则左式堆中至少包含2^d - 1个内部节点, 2^(d + 1) - 1个节点
  - 反之, 若一个左式堆的规模为n, 则右侧链长度d的长度为O(logn)
- merge合并
  - 左式堆的合并即为将两个左式堆进行合并
  - 大致步骤(递归)
    - 将两个堆(a堆, b堆, 且a堆根优先级 >= b堆)进行合并可以被分解为将a堆的右子树与b堆合并
    - 再将合并的堆归为a堆的右子树
    - 递归基: a堆的右子树 == null || b堆的右子树 == null
  - 时间复杂度
    - T(n) = O(右侧链长度) = O(logn)

- insert
  - insert操作可以看做是一个规模为1的左式堆与原左式堆的合并操作
  - 因此只需要调用以及实现的merge便可实现insert
- delMax
  - 删除掉根节点的左式堆其实就变成了两个左式堆
  - 因此只需要在删除根节点后调用merge即可实现delMax

# 串(String)

- 定义

  - 串是由字符组成的有限序列

- 特点

  - 串的元素的组成种类不多, 通常串长n >> 元素种类数|∑|

- 术语规定

  - 子串substr
    - substr(i, k) = 字符串中的[i, i + k)的字符
    - *此定义与Java中的substr不同, Java中为substr(int beginIndex, int endIndex)*
  - 前缀prefix
    - prefix(k) = substr(0, k)
  - 后缀suffix
    - suffix(k) = substr(n - k, k)

  - 空串
    - 长度为0的串: `""`
    - 规定空串是任何串的子串, 前缀, 后缀
  - 规定: 任何串是其自身的子串, 前缀, 后缀
  - 真子串, 真前缀, 真后缀
    - 长度严格小于自身的子串, 前缀, 后缀

## 串匹配

- 串匹配是字符串中十分常见的问题, 如在Java中就为String提供了indexOf方法
- 定义(Java)
  - `int indexOf(String str)`
  - 在原字符串的所有子串中, 第一个与str相同的子串的第一个元素的位置
- 问题研究的层次
  1. detection
     - str是否在原字符串中出现
  2. location
     - 首次在哪里出现
     - 该层次是本章研究的重点
  3. counting
     - 共有几次出现
  4. enumeration
     - 各次在哪里出现
- BF算法
  - BF算法是最低效的算法
  - 大致步骤
    - 每次一个单位地移动模式串
    - 每移动一次, 就将其与之对其的那一部分主串进行比较
    - 比较成功则返回结果, 失败就继续移动模式串
  - 效率: O(n * m)
- KMP算法
  - next表
    - 记录失配在模式串的第j个位置时, 在主串中失配的字符的前j个字符都是已知的, 根据这一特点可以预知接下来的一些比对是无意义的, 而直接略过
    - next表则记录失配在模式串的第j个位置时, 需要将j重置到哪个位置(此时i不变)
  - 效率: O(n)
- BM算法

  - bc表

    - 记录在主字符串的字符c失败时, 这个字符c在模式串的lastIndex(从右到左的第一个BadCharacter的位置)

    - 并移动模式串使模式串的这个字符c与失配的主串的字符c对其
    - 若移动使模式串回溯(在原来的基础上左移), 则放弃这次移动, 而将模式串右移一个位置
    - 若在模式串中没有这个字符c, 则直接将模式串右移至主串的这个字符c的右一个位置

  - gs表

    - 单使用bc表的算法为BM算法, 使用bc表的同时使用gs表的算法为BM_GS算法
    - gs表借鉴了KMP算法的next表的思想, 当一次匹配失败在模式串的第j个位置时, 在主串中失配的字符后的m - j个字符都是已知的, 因此可以根据这一点构建出类似于next表的gs表, 略过一些比对

  - 效率

    - BM_GS: 优于O(n)
    - BM: O(n/m) ~ O(n * m)
- Karp_Rabin算法
  - Karp_Rabin算法利用了数的特点
    - 数与数之间的比较为O(1)
    - 将组成串的所有可能元素分别从0到|∑| - 1依次对应, 则一个串可以由|∑|进制表示
  - 大致步骤
    - 将模式串换算为对应的|∑|进制数, 转为10进制后对其hash, 得到其指纹
    - 依次求出主串的子串的指纹, 与模式串比对, 当指纹相同时, 再逐个字符进行比较